{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryCLassificationKeras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adOn-9zRUcsd",
        "outputId": "aa3df4f6-5003-4320-90c7-e5699ed3ee1c"
      },
      "source": [
        "# Mounting over google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"TwitterSupport\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at TwitterSupport\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3luTLJe72tg"
      },
      "source": [
        "# importing required libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR1NQG8EVHo4"
      },
      "source": [
        "# Setting up the root DIR\n",
        "ROOT_DIR=\"TwitterSupport/MyDrive/TwitterSupport/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q3q8ysv8iPJ"
      },
      "source": [
        "# Reading Dataset\n",
        "data = pd.read_csv(ROOT_DIR+'dataset/Tweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "8VyQhrvn8z7t",
        "outputId": "932c7cd8-5f71-43eb-897b-f3dbb9b1a8a3"
      },
      "source": [
        "# Reading top rows\n",
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxmcGCxm87Ct",
        "outputId": "d935c86b-1ce0-4f5b-b0b5-fe99722fc198"
      },
      "source": [
        "# we check how much null entries in each columns\n",
        "print(\"data_is_null \\n\",data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_is_null \n",
            " tweet_id                            0\n",
            "airline_sentiment                   0\n",
            "airline_sentiment_confidence        0\n",
            "negativereason                   5462\n",
            "negativereason_confidence        4118\n",
            "airline                             0\n",
            "airline_sentiment_gold          14600\n",
            "name                                0\n",
            "negativereason_gold             14608\n",
            "retweet_count                       0\n",
            "text                                0\n",
            "tweet_coord                     13621\n",
            "tweet_created                       0\n",
            "tweet_location                   4733\n",
            "user_timezone                    4820\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_q3lNTf9JNO"
      },
      "source": [
        " #Keeping only the neccessary columns\n",
        "data = data[['text','airline_sentiment']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXjJF2GX9Y5Y",
        "outputId": "b0c16781-3cdf-4ff6-cd53-7d31749ea5f6"
      },
      "source": [
        "data['text'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@VirginAmerica What @dhepburn said.',\n",
              "       \"@VirginAmerica plus you've added commercials to the experience... tacky.\",\n",
              "       \"@VirginAmerica I didn't today... Must mean I need to take another trip!\",\n",
              "       ...,\n",
              "       '@AmericanAir Please bring American Airlines to #BlackBerry10',\n",
              "       \"@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\",\n",
              "       '@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "BAkGbDwc9vWP",
        "outputId": "d76e200b-5bd0-4166-8c3b-e10f132e046b"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14640</td>\n",
              "      <td>14640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>14427</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>@united thanks</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>6</td>\n",
              "      <td>9178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text airline_sentiment\n",
              "count            14640             14640\n",
              "unique           14427                 3\n",
              "top     @united thanks          negative\n",
              "freq                 6              9178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GC4hzP7-HPm"
      },
      "source": [
        "# it will remove all Neutral values from data\n",
        "data = data[data.airline_sentiment != \"neutral\"].copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "grY2PLtV-dI9",
        "outputId": "9f73457a-4d9c-4d9d-8176-52bf356213d6"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11541</td>\n",
              "      <td>11541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>11381</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>@AmericanAir thanks</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>9178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       text airline_sentiment\n",
              "count                 11541             11541\n",
              "unique                11381                 2\n",
              "top     @AmericanAir thanks          negative\n",
              "freq                      5              9178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce77nOif0TSQ"
      },
      "source": [
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "from nltk import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Mc_zJAyIyP"
      },
      "source": [
        "# Cleaning Text\n",
        "\n",
        "def clean_text(txt):\n",
        "\n",
        "          \"\"\"\n",
        "          removing all hashtags , punctuations, stop_words  and links, also stemming words\n",
        "          \"\"\"\n",
        "          from nltk.corpus import stopwords\n",
        "          txt = txt.lower()\n",
        "          txt = re.sub(r\"(?<=\\w)nt\", \"not\",txt) #change don't to do not cna't to cannot\n",
        "          txt = re.sub(r\"(@\\S+)\", \"\", txt)  # remove hashtags\n",
        "          txt = re.sub(r'\\W', ' ', str(txt)) # remove all special characters including apastrophie\n",
        "          txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations\n",
        "          txt = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)   # remove all single characters (it's -> it s then we need to remove s)\n",
        "          txt = re.sub(r'\\s+', ' ', txt, flags=re.I) # Substituting multiple spaces with single space\n",
        "          txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links\n",
        "          txt = ' '.join([PorterStemmer().stem(word=word) for word in txt.split(\" \") if word not in stopwords.words('english') ]) # stem & remove stop words\n",
        "          txt = ''.join([i for i in txt if not i.isdigit()]).strip() # remove digits ()\n",
        "          return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCUhrqrb_Ukk"
      },
      "source": [
        "# Data Cleaning\n",
        "data['text'] = data['text'].apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu8S1akZ6wGV",
        "outputId": "81c5981d-f41c-49c9-90b7-c905e1dc5726"
      },
      "source": [
        "data['text'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['plu ad commerci experi tacki',\n",
              "       'realli aggress blast obnoxi enotertainmenot guest face amp littl recours',\n",
              "       'realli big bad thing', ..., 'thank got differenot flight chicago',\n",
              "       'leav  minut late flight warn commun unotil  minut late flight call shitti custom svc',\n",
              "       'money chang flight answer phone suggest make commitmenot'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL-iybFtx1PI"
      },
      "source": [
        "# Embedding words to text sequences\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "# pad: to make all input of same length\n",
        "X = pad_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFrDam0QUyRD",
        "outputId": "887959ec-4679-41d6-8b9d-c8d6065a3f9d"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11541, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FQt1z9B_26A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed161da-fcfd-4d10-a68c-38fb94accd68"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "input_len = 21\n",
        "import time\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim, input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dox8zvNrAJTd",
        "outputId": "25f0f049-aebf-4ea6-b03d-6c6bb6648d56"
      },
      "source": [
        "start=time.time()\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(\"Time to compile model:\",time.time()-start)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to compile model: 0.01389765739440918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtAee7k3AOE_",
        "outputId": "173da178-e49b-45bc-c9a1-0ce91410dd23"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 21, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 21, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDCnvVHjAnmV",
        "outputId": "681be885-cd36-41b4-fd13-d381db72fffa"
      },
      "source": [
        "Y = pd.get_dummies(data['airline_sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.15, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9809, 21) (9809, 2)\n",
            "(1732, 21) (1732, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Y6wTpRAx42",
        "outputId": "698e158d-62f6-495c-c1c4-1214fc88a68e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "batch_size = 32\n",
        "tqdm(model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "307/307 - 54s - loss: 0.3280 - accuracy: 0.8669\n",
            "Epoch 2/7\n",
            "307/307 - 28s - loss: 0.1883 - accuracy: 0.9236\n",
            "Epoch 3/7\n",
            "307/307 - 29s - loss: 0.1541 - accuracy: 0.9384\n",
            "Epoch 4/7\n",
            "307/307 - 29s - loss: 0.1348 - accuracy: 0.9476\n",
            "Epoch 5/7\n",
            "307/307 - 29s - loss: 0.1168 - accuracy: 0.9534\n",
            "Epoch 6/7\n",
            "307/307 - 28s - loss: 0.1021 - accuracy: 0.9594\n",
            "Epoch 7/7\n",
            "307/307 - 29s - loss: 0.0905 - accuracy: 0.9622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYA9Y6OBBEpB",
        "outputId": "2c82d4f0-6923-47bd-e3a5-8ed475963481"
      },
      "source": [
        "validation_size = 1500\n",
        "\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 - 2s - loss: 0.2771 - accuracy: 0.9059\n",
            "score: 0.28\n",
            "acc: 0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgCxIXhkBFXQ"
      },
      "source": [
        "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 0)[0]\n",
        "   \n",
        "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "        if np.argmax(Y_validate[x]) == 0:\n",
        "            neg_correct += 1\n",
        "        else:\n",
        "            pos_correct += 1\n",
        "       \n",
        "    if np.argmax(Y_validate[x]) == 0:\n",
        "        neg_cnt += 1\n",
        "    else:\n",
        "        pos_cnt += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y172VZeLYxEB",
        "outputId": "8f38f1a2-809c-4baf-b32b-75b6b9f960ac"
      },
      "source": [
        "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
        "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_acc 73.75886524822694 %\n",
            "neg_acc 94.08866995073892 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G22jePTOBRuU",
        "outputId": "98ac309b-fe8c-4bad-c1b4-26554e2a3d4b"
      },
      "source": [
        "twt = ['Meetings: ram is a bad man.']\n",
        "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
        "twt = tokenizer.texts_to_sequences(twt)\n",
        "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
        "twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n",
        "print(twt)\n",
        "sentiment = model.predict(twt,batch_size=1,verbose = 0)[0]\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"negative\")\n",
        "elif (np.argmax(sentiment) == 1):\n",
        "    print(\"positive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0 459 113 754]]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 21) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (1, 28).\n",
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eTPZeC2DkRx"
      },
      "source": [
        "import pickle\n",
        "\n",
        "#saving model\n",
        "model.save(ROOT_DIR+\"binaryClassificationModel.h5\")\n",
        "\n",
        "# saving tokenizer\n",
        "with open(ROOT_DIR+'tokenizerBinaryClassification.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz-vPKwbhgOh"
      },
      "source": [
        "import pickle\n",
        "import tensorflow.keras.models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "#Text Preprocessing\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "class BinaryInference:\n",
        "\n",
        "      def __init__(self):\n",
        "          self.load_models()\n",
        "\n",
        "      def get_model(self):\n",
        "          max_fatures = 2000\n",
        "          embed_dim = 128\n",
        "          lstm_out = 196\n",
        "          input_len = 21\n",
        "          model = Sequential()\n",
        "          model.add(Embedding(max_fatures, embed_dim,input_length = input_len))\n",
        "          model.add(SpatialDropout1D(0.4))\n",
        "          model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "          model.add(Dense(2,activation='softmax'))\n",
        "          model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "          return model\n",
        "\n",
        "      def clean_text(self, txt):\n",
        "\n",
        "          \"\"\"\n",
        "          removing all hashtags , punctuations, stop_words  and links, also stemming words\n",
        "          \"\"\"\n",
        "          from nltk.corpus import stopwords\n",
        "          txt = txt.lower()\n",
        "          txt = re.sub(r\"(?<=\\w)nt\", \"not\",txt) #change don't to do not cna't to cannot\n",
        "          txt = re.sub(r\"(@\\S+)\", \"\", txt)  # remove hashtags\n",
        "          txt = re.sub(r'\\W', ' ', str(txt)) # remove all special characters including apastrophie\n",
        "          txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations\n",
        "          txt = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)   # remove all single characters (it's -> it s then we need to remove s)\n",
        "          txt = re.sub(r'\\s+', ' ', txt, flags=re.I) # Substituting multiple spaces with single space\n",
        "          txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links\n",
        "          txt = ' '.join([PorterStemmer().stem(word=word) for word in txt.split(\" \") if word not in stopwords.words('english') ]) # stem & remove stop words\n",
        "          txt = ''.join([i for i in txt if not i.isdigit()]).strip() # remove digits ()\n",
        "          return txt\n",
        "\n",
        "      def load_models(self):\n",
        "          with open(ROOT_DIR+'tokenizerBinaryClassification.pickle', 'rb') as handle:\n",
        "              self.tokenizer = pickle.load(handle)\n",
        "\n",
        "          self.model = self.get_model()\n",
        "          self.model.load_weights(ROOT_DIR+\"binaryClassificationModel.h5\")\n",
        "\n",
        "\n",
        "      def predict_complaint(self, text):\n",
        "\n",
        "          #vectorizing the tweet by the pre-fitted tokenizer instance\n",
        "          text = self.clean_text(text)\n",
        "          twt = self.tokenizer.texts_to_sequences([text])\n",
        "          #padding the tweet to have exactly the same shape as `embedding_2` input\n",
        "          twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n",
        "          complain = self.model.predict(twt,batch_size=1,verbose = 0)[0]\n",
        "          if(np.argmax(complain) == 0):\n",
        "              print(\"negative\")\n",
        "              return True\n",
        "          elif (np.argmax(complain) == 1):\n",
        "              print(\"positive\")\n",
        "              return False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5wGZeueOMM"
      },
      "source": [
        "bi = BinaryInference()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsco2lIOeXDb",
        "outputId": "7da0dadd-e180-402a-d8a8-ab4bcb6d1468"
      },
      "source": [
        "bi.predict_complaint(\"americanair leaving over 20 minutes late flight no warnings or communication until we were 15 minutes late flight thats called shitty customer svc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 21) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (1, 28).\n",
            "negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdTaR-MFeocF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKROeRvVdXnB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
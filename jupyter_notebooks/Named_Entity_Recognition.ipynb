{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named_Entity_Recognition (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a-uIL0i2RPx",
        "outputId": "1cde6c40-788d-4698-9536-09fa4f602671"
      },
      "source": [
        "# Mounting over google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"TwitterSupport\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at TwitterSupport\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK5-BDR521VH"
      },
      "source": [
        "# Root dir\n",
        "ROOT_DIR=\"TwitterSupport/MyDrive/TwitterSupport/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zotabHXSc8N"
      },
      "source": [
        "#Named Entity Recognition \n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOdm5qnZ1f_B"
      },
      "source": [
        "# training data\n",
        "TRAIN_DATA = [\n",
        "              (\"Walmart is a leading e-commerce company\", {\"entities\": [(0, 7, \"ORG\")]}),\n",
        "              (\"I reached Chennai yesterday.\", {\"entities\": [(19, 28, \"GPE\")]}),\n",
        "              (\"I recently ordered a book from Amazon\", {\"entities\": [(24,32, \"ORG\")]}),\n",
        "              (\"I was driving a BMW\", {\"entities\": [(16,19, \"PRODUCT\")]}),\n",
        "              (\"I ordered this from ShopClues\", {\"entities\": [(20,29, \"ORG\")]}),\n",
        "              (\"Fridge can be ordered in Amazon \", {\"entities\": [(0,6, \"PRODUCT\")]}),\n",
        "              (\"I bought a new Washer\", {\"entities\": [(16,22, \"PRODUCT\")]}),\n",
        "              (\"I bought a old table\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"I bought a fancy dress\", {\"entities\": [(18,23, \"PRODUCT\")]}),\n",
        "              (\"I rented a camera\", {\"entities\": [(12,18, \"PRODUCT\")]}),\n",
        "              (\"I rented a tent for our trip\", {\"entities\": [(12,16, \"PRODUCT\")]}),\n",
        "              (\"I rented a screwdriver from our neighbour\", {\"entities\": [(12,22, \"PRODUCT\")]}),\n",
        "              (\"I repaired my computer\", {\"entities\": [(15,23, \"PRODUCT\")]}),\n",
        "              (\"I got my clock fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"I got my truck fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"Flipkart started it's journey from zero\", {\"entities\": [(0,8, \"ORG\")]}),\n",
        "              (\"I recently ordered from Max\", {\"entities\": [(24,27, \"ORG\")]}),\n",
        "              (\"Flipkart is recognized as leader in market\",{\"entities\": [(0,8, \"ORG\")]}),\n",
        "              (\"Virgin America is recognized as leader in market\",{\"entities\": [(0,14, \"ORG\")]}),\n",
        "              (\"Virgin America is the best airline ever\",{\"entities\": [(0,14, \"ORG\")]}),\n",
        "              (\"I recently ordered from Swiggy\", {\"entities\": [(24,29, \"ORG\")]}),\n",
        "              (\"Projectpro_test is a great airline.\", {\"entities\" : [(0,15, \"ORG\")]}),\n",
        "              (\"Projectpro_test is a great airline.\", {\"entities\" : [(0,15, \"ORG\")]}),\n",
        "              (\"Projectpro_test is a great airline.\", {\"entities\" : [(0,15, \"ORG\")]}),\n",
        "              (\"Projectpro_test is a great airline.\", {\"entities\" : [(0,15, \"ORG\")]})\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CflY7Ytu156j"
      },
      "source": [
        "# Disable pipeline components you dont need to change\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkSzKb8d1et6",
        "outputId": "3c089f13-92f9-40eb-f18c-6fb359dc2aae"
      },
      "source": [
        " import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from pathlib import Path\n",
        "\n",
        "# TRAINING THE MODEL\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "\n",
        "  # Training for 30 iterations\n",
        "  for iteration in range(30):\n",
        "\n",
        "    # shuufling examples  before every iteration\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(\n",
        "                    texts,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=0.5,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "        print(\"Losses\", losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 5.098098905153165}\n",
            "Losses {'ner': 12.230556102796982}\n",
            "Losses {'ner': 13.75167132565366}\n",
            "Losses {'ner': 15.848025918652638}\n",
            "Losses {'ner': 19.49425376934778}\n",
            "Losses {'ner': 25.13032833158468}\n",
            "Losses {'ner': 25.209815079420878}\n",
            "Losses {'ner': 0.0697075542411767}\n",
            "Losses {'ner': 2.1810758713108953}\n",
            "Losses {'ner': 5.205351497599622}\n",
            "Losses {'ner': 9.859327055135509}\n",
            "Losses {'ner': 11.048176070529735}\n",
            "Losses {'ner': 17.126382625603583}\n",
            "Losses {'ner': 18.741598498841945}\n",
            "Losses {'ner': 0.6426653625094332}\n",
            "Losses {'ner': 0.779853617597837}\n",
            "Losses {'ner': 2.2639738549002004}\n",
            "Losses {'ner': 4.159977092317263}\n",
            "Losses {'ner': 8.88356231795899}\n",
            "Losses {'ner': 13.680505505672613}\n",
            "Losses {'ner': 13.883825901407818}\n",
            "Losses {'ner': 4.897011601451283}\n",
            "Losses {'ner': 5.024953328834869}\n",
            "Losses {'ner': 8.528766405934704}\n",
            "Losses {'ner': 10.817291322330249}\n",
            "Losses {'ner': 13.816531997107205}\n",
            "Losses {'ner': 14.721547621084511}\n",
            "Losses {'ner': 14.751109501637274}\n",
            "Losses {'ner': 0.15957696171244606}\n",
            "Losses {'ner': 2.0448157932207494}\n",
            "Losses {'ner': 5.780327108741602}\n",
            "Losses {'ner': 7.182575061621009}\n",
            "Losses {'ner': 10.555974875436476}\n",
            "Losses {'ner': 13.83887450496806}\n",
            "Losses {'ner': 13.84142299752871}\n",
            "Losses {'ner': 0.0051113742333654955}\n",
            "Losses {'ner': 2.0846881205707177}\n",
            "Losses {'ner': 4.063443420969634}\n",
            "Losses {'ner': 7.232128844718318}\n",
            "Losses {'ner': 7.278282325419241}\n",
            "Losses {'ner': 11.574837581011707}\n",
            "Losses {'ner': 11.576905532113187}\n",
            "Losses {'ner': 2.274338326417819}\n",
            "Losses {'ner': 2.4036882227092065}\n",
            "Losses {'ner': 3.996707615977357}\n",
            "Losses {'ner': 7.297804622930016}\n",
            "Losses {'ner': 8.287230348948896}\n",
            "Losses {'ner': 10.04858073613238}\n",
            "Losses {'ner': 10.049135163543061}\n",
            "Losses {'ner': 0.35324166604550555}\n",
            "Losses {'ner': 1.5813716949924128}\n",
            "Losses {'ner': 2.1746211072002097}\n",
            "Losses {'ner': 2.2087487979640628}\n",
            "Losses {'ner': 2.90702346230114}\n",
            "Losses {'ner': 4.655559339496676}\n",
            "Losses {'ner': 4.65777840406804}\n",
            "Losses {'ner': 0.00016964258716001268}\n",
            "Losses {'ner': 0.7138028601174469}\n",
            "Losses {'ner': 0.7479554042160386}\n",
            "Losses {'ner': 4.688687344938383}\n",
            "Losses {'ner': 5.645614341511508}\n",
            "Losses {'ner': 14.393315746794741}\n",
            "Losses {'ner': 14.393325929128965}\n",
            "Losses {'ner': 1.5859901867597728}\n",
            "Losses {'ner': 2.917380374377073}\n",
            "Losses {'ner': 2.9339279663882802}\n",
            "Losses {'ner': 5.021917614905631}\n",
            "Losses {'ner': 5.024543934143109}\n",
            "Losses {'ner': 7.709337773034774}\n",
            "Losses {'ner': 7.718619293725144}\n",
            "Losses {'ner': 0.8465638119458965}\n",
            "Losses {'ner': 2.665992968055578}\n",
            "Losses {'ner': 2.6722948237274284}\n",
            "Losses {'ner': 2.7101991381898802}\n",
            "Losses {'ner': 2.7128412004488656}\n",
            "Losses {'ner': 2.736890730382031}\n",
            "Losses {'ner': 3.2679433709181267}\n",
            "Losses {'ner': 1.9633326425921904}\n",
            "Losses {'ner': 4.172704102310532}\n",
            "Losses {'ner': 5.079413622389515}\n",
            "Losses {'ner': 5.079429832210437}\n",
            "Losses {'ner': 5.290734190466182}\n",
            "Losses {'ner': 5.290821734843029}\n",
            "Losses {'ner': 5.290821744757219}\n",
            "Losses {'ner': 0.023961462747529028}\n",
            "Losses {'ner': 0.023974592230860816}\n",
            "Losses {'ner': 2.6263884000430515}\n",
            "Losses {'ner': 2.6264453559800796}\n",
            "Losses {'ner': 2.6512582404519467}\n",
            "Losses {'ner': 2.657087427291157}\n",
            "Losses {'ner': 2.6570875085858114}\n",
            "Losses {'ner': 0.0006170209758170897}\n",
            "Losses {'ner': 0.0008104252298725412}\n",
            "Losses {'ner': 0.023491790763422657}\n",
            "Losses {'ner': 3.32102898998805}\n",
            "Losses {'ner': 4.624994598767602}\n",
            "Losses {'ner': 4.625100733966484}\n",
            "Losses {'ner': 4.625100763234019}\n",
            "Losses {'ner': 0.014247155308938275}\n",
            "Losses {'ner': 0.014297680412215425}\n",
            "Losses {'ner': 0.8179853681544671}\n",
            "Losses {'ner': 1.283955309122221}\n",
            "Losses {'ner': 1.289746680549606}\n",
            "Losses {'ner': 2.738162614429755}\n",
            "Losses {'ner': 2.73816277669328}\n",
            "Losses {'ner': 1.8832065071759105}\n",
            "Losses {'ner': 3.328688372377056}\n",
            "Losses {'ner': 3.466177099684434}\n",
            "Losses {'ner': 4.89736592838715}\n",
            "Losses {'ner': 4.897432105680895}\n",
            "Losses {'ner': 5.62831506864119}\n",
            "Losses {'ner': 5.628315268752449}\n",
            "Losses {'ner': 0.00014298659724631957}\n",
            "Losses {'ner': 1.191922426906856}\n",
            "Losses {'ner': 1.254748257539718}\n",
            "Losses {'ner': 1.6151280889610846}\n",
            "Losses {'ner': 1.6166931652539356}\n",
            "Losses {'ner': 1.6167700438342865}\n",
            "Losses {'ner': 2.6607209592546965}\n",
            "Losses {'ner': 1.6220101276131726}\n",
            "Losses {'ner': 1.6252212729766775}\n",
            "Losses {'ner': 1.626274062334148}\n",
            "Losses {'ner': 1.6273240727367932}\n",
            "Losses {'ner': 4.27825290868554}\n",
            "Losses {'ner': 4.324079399335491}\n",
            "Losses {'ner': 4.324079431321149}\n",
            "Losses {'ner': 3.197866623595724e-05}\n",
            "Losses {'ner': 0.010262566098968154}\n",
            "Losses {'ner': 2.737740155441389}\n",
            "Losses {'ner': 2.737740944551567}\n",
            "Losses {'ner': 2.737933880042944}\n",
            "Losses {'ner': 2.787265745004517}\n",
            "Losses {'ner': 3.176718577463032}\n",
            "Losses {'ner': 2.2937528920841386}\n",
            "Losses {'ner': 2.2938102220089593}\n",
            "Losses {'ner': 3.301453934200557}\n",
            "Losses {'ner': 3.301837868324793}\n",
            "Losses {'ner': 3.301838392600923}\n",
            "Losses {'ner': 3.30186122681407}\n",
            "Losses {'ner': 3.302670219581183}\n",
            "Losses {'ner': 1.6728910818551919}\n",
            "Losses {'ner': 1.673390455534837}\n",
            "Losses {'ner': 1.6733905619710387}\n",
            "Losses {'ner': 1.6736545598679653}\n",
            "Losses {'ner': 1.673913550873395}\n",
            "Losses {'ner': 1.6739244705530167}\n",
            "Losses {'ner': 1.673934501890986}\n",
            "Losses {'ner': 0.11186241571182265}\n",
            "Losses {'ner': 0.11186378985168342}\n",
            "Losses {'ner': 1.9188652858087687}\n",
            "Losses {'ner': 1.9188693194370583}\n",
            "Losses {'ner': 1.9188752136347529}\n",
            "Losses {'ner': 1.9191070670447563}\n",
            "Losses {'ner': 1.9195859602481373}\n",
            "Losses {'ner': 0.00010039526888094841}\n",
            "Losses {'ner': 0.0009656795247304649}\n",
            "Losses {'ner': 0.15203358849950666}\n",
            "Losses {'ner': 0.15390856546269555}\n",
            "Losses {'ner': 1.652464369170711}\n",
            "Losses {'ner': 1.6524709093897214}\n",
            "Losses {'ner': 1.6524717283169164}\n",
            "Losses {'ner': 8.587939364920749e-05}\n",
            "Losses {'ner': 0.003419838875124799}\n",
            "Losses {'ner': 0.03887104891804927}\n",
            "Losses {'ner': 0.03887140994298141}\n",
            "Losses {'ner': 0.03967816585770207}\n",
            "Losses {'ner': 0.04241781216555824}\n",
            "Losses {'ner': 0.04244017725014882}\n",
            "Losses {'ner': 8.713489388651602e-07}\n",
            "Losses {'ner': 1.2754655661029506e-06}\n",
            "Losses {'ner': 0.00040070750985364177}\n",
            "Losses {'ner': 0.0065273727530120555}\n",
            "Losses {'ner': 0.03679023667660447}\n",
            "Losses {'ner': 0.1467154402126699}\n",
            "Losses {'ner': 0.14789147942157835}\n",
            "Losses {'ner': 0.15103792214917178}\n",
            "Losses {'ner': 0.15103815000583096}\n",
            "Losses {'ner': 0.1511189642789711}\n",
            "Losses {'ner': 0.9548974237646936}\n",
            "Losses {'ner': 0.9579124083686963}\n",
            "Losses {'ner': 0.9580356876077938}\n",
            "Losses {'ner': 0.9580356876084378}\n",
            "Losses {'ner': 8.574529686557978e-06}\n",
            "Losses {'ner': 0.0003210540544652954}\n",
            "Losses {'ner': 0.0003212500884593965}\n",
            "Losses {'ner': 0.5700400951305724}\n",
            "Losses {'ner': 1.9724032356733885}\n",
            "Losses {'ner': 2.010024007930185}\n",
            "Losses {'ner': 2.0100240167693464}\n",
            "Losses {'ner': 9.059438596075754e-06}\n",
            "Losses {'ner': 0.004961876541704138}\n",
            "Losses {'ner': 0.006730072546592858}\n",
            "Losses {'ner': 0.006732597540958756}\n",
            "Losses {'ner': 0.006866833670084241}\n",
            "Losses {'ner': 0.0068674257441274245}\n",
            "Losses {'ner': 0.006867425749888304}\n",
            "Losses {'ner': 4.283521596635132e-05}\n",
            "Losses {'ner': 9.102271720385236e-05}\n",
            "Losses {'ner': 9.757753355811756e-05}\n",
            "Losses {'ner': 0.00048395433478598727}\n",
            "Losses {'ner': 0.19880624342440611}\n",
            "Losses {'ner': 0.6409236434114721}\n",
            "Losses {'ner': 0.6409360017846754}\n",
            "Losses {'ner': 0.0010320606847813675}\n",
            "Losses {'ner': 0.0010320620788692274}\n",
            "Losses {'ner': 0.6940521304075536}\n",
            "Losses {'ner': 1.7184612767640703}\n",
            "Losses {'ner': 1.7188257011216816}\n",
            "Losses {'ner': 1.7573682484368138}\n",
            "Losses {'ner': 1.757435592619761}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpex0fSq2C-a",
        "outputId": "2e68cb86-ccff-4e8b-bf54-368aa4c4d904"
      },
      "source": [
        "doc = nlp(\"I was driving a Projectpro_test\")\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entities [('Projectpro_test', 'ORG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuxZhoy_2Mqt",
        "outputId": "ea1b60dd-8ac7-41ae-d80b-64a2cf373eeb"
      },
      "source": [
        "# Save the  model to directory\n",
        "output_dir = Path(ROOT_DIR+'model_NER/')\n",
        "nlp.to_disk(output_dir)\n",
        "print(\"Saved model to\", output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to TwitterSupport/MyDrive/TwitterSupport/model_NER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hnAtmGP2MvU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6030c42a-b405-4a58-b0ba-db28e067e9a2"
      },
      "source": [
        "camel_case_split(\"VirginAmerica\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@Virgin America'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qVUlkUGyVpk"
      },
      "source": [
        "def camel_case_split(str):\n",
        "    words = [[str[0]]]\n",
        "  \n",
        "    for c in str[1:]:\n",
        "        if words[-1][-1].islower() and c.isupper():\n",
        "            words.append(list(c))\n",
        "        else:\n",
        "            words[-1].append(c)\n",
        "  \n",
        "    return \" \".join([''.join(word) for word in words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GZl-ZpyyyZo"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text( txt):\n",
        "    \n",
        "      \"\"\"\n",
        "      removing all hashtags , punctuations, stop_words  and links, also stemming words \n",
        "      \"\"\"\n",
        "      txt = \" \".join([camel_case_split(t) for t in txt.split(\" \")])\n",
        "      txt = re.sub(r\"(?<=\\w)nt\", \"not\",txt) #change don't to do not cna't to cannot \n",
        "      txt = re.sub(r'\\W', ' ', str(txt)) # remove all special characters including apastrophie \n",
        "      txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations \n",
        "      txt = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)   # remove all single characters (it's -> it s then we need to remove s)\n",
        "      txt = re.sub(r'\\s+', ' ', txt, flags=re.I) # Substituting multiple spaces with single space\n",
        "      txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links \n",
        "      return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ms6ez7hQygSu",
        "outputId": "a40b8d11-de7f-42d9-c378-e36d8d7d51aa"
      },
      "source": [
        "clean_text(\"@VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select???\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Virgin America why are your first fares in May over three times more than other carriers when all seats are available to select '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmidM4tiUa5Y",
        "outputId": "e461cd7b-4da9-4f2e-9f7f-28bd17d386ab"
      },
      "source": [
        "doc = nlp(' Virgin America why are your first indian airline fares in May over three times more than other carriers when all seats are available to select ')\n",
        "print([(X.text, X.label_) for X in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Virgin America', 'ORG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmtJrVX_4QxS"
      },
      "source": [
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8eoDWF6yU_i",
        "outputId": "8529d92a-138a-45be-a3df-e2fd98f17bed"
      },
      "source": [
        "doc = nlp(' Virgin America why are your first indian airline fares in May over three times more than other carriers when all seats are available to select ')\n",
        "print([(X.text, X.label_) for X in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Virgin America', 'LOC'), ('first', 'ORDINAL'), ('indian', 'NORP'), ('May', 'DATE'), ('three', 'CARDINAL')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZWJ5OZvUqb5"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "import re\n",
        "import string\n",
        "from pathlib import Path\n",
        "\n",
        "class NameEntities:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "      # ROOT_DIR = \"\"\n",
        "      self.nlp = en_core_web_sm.load() # Load the saved model and predict\n",
        "      output_dir = Path(ROOT_DIR+'model_NER/')\n",
        "      print(\"Loading from\", output_dir)\n",
        "      self.nlp_updated = spacy.load(output_dir)\n",
        "\n",
        "  def clean_text(self, txt):\n",
        "      \"\"\"\n",
        "      removing all hashtags , punctuations, stop_words  and links, also stemming words \n",
        "      \"\"\"\n",
        "      txt = \" \".join([self.camel_case_split(t) for t in txt.split(\" \")])\n",
        "      txt = re.sub(r\"(?<=\\w)nt\", \"not\",txt) #change don't to do not cna't to cannot \n",
        "      txt = re.sub(r'\\W', ' ', str(txt)) # remove all special characters including apastrophie \n",
        "      txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations \n",
        "      txt = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)   # remove all single characters (it's -> it s then we need to remove s)\n",
        "      txt = re.sub(r'\\s+', ' ', txt, flags=re.I) # Substituting multiple spaces with single space\n",
        "      txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links \n",
        "      return txt\n",
        "\n",
        "\n",
        "  def camel_case_split(self, str):\n",
        "    words = [[str[0]]]\n",
        "  \n",
        "    for c in str[1:]:\n",
        "        if words[-1][-1].islower() and c.isupper():\n",
        "            words.append(list(c))\n",
        "        else:\n",
        "            words[-1].append(c)\n",
        "  \n",
        "    return \" \".join([''.join(word) for word in words])\n",
        "\n",
        "  \n",
        "  def get_Entities(self, text):\n",
        "      text = self.clean_text(text)\n",
        "      doc = self.nlp_updated(text)\n",
        "      labels = [(X.text, X.label_) for X in doc.ents]\n",
        "\n",
        "      doc = self.nlp(text)\n",
        "      labels_norm = [(X.text, X.label_) for X in doc.ents]\n",
        "      labels.extend(labels_norm)\n",
        "\n",
        "      return labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmQ0pXgz1Va9",
        "outputId": "249e0723-eef0-489b-92c7-14acfc1b5486"
      },
      "source": [
        "ner = NameEntities()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from TwitterSupport/MyDrive/TwitterSupport/model_NER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5qCf68N1dKy",
        "outputId": "7edb97fd-cad1-448e-9512-6de482108e24"
      },
      "source": [
        "ner.get_Entities(\"Projectpro_test is a good airline\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Projectprotest', 'ORG'), ('Projectprotest', 'ORG')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQEl_kt31zM5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}